{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a06cd1d4",
   "metadata": {},
   "source": [
    "## Notebook for calculating Mask Consistency Score for GAN-transformed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "900e2b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import glob, os\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "#from keras.preprocessing.image import img_to_array, array_to_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd58ed4",
   "metadata": {},
   "source": [
    "## 1. Resize GAN-transformed Dataset to 1024*1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00c6def",
   "metadata": {},
   "source": [
    "#### 1.1 Specify Args: Directory, folder name and the new image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bab0c67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'A2B_FID'\n",
    "image_size = 1024\n",
    "dir = '/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Powertrain14_Blattfeder/Results/training4_batch4_400trainA_250trainB/samples_testing'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b400c36",
   "metadata": {},
   "source": [
    "#### 1.2 Create new Folder \"/A2B_FID_1024\" in Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "520e04ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_folder = (os.path.join(dir, folder))\n",
    "new_folder = (os.path.join(dir, folder+'_'+str(image_size)))\n",
    "\n",
    "if not os.path.exists(new_folder):\n",
    "    try:\n",
    "        os.mkdir(new_folder)\n",
    "    except FileExistsError:\n",
    "        print('Folder already exists')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76b37952",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Powertrain14_Blattfeder/Results/training4_batch4_400trainA_250trainB/samples_testing/A2B_FID\n",
      "/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Powertrain14_Blattfeder/Results/training4_batch4_400trainA_250trainB/samples_testing/A2B_FID_1024\n"
     ]
    }
   ],
   "source": [
    "print(os.path.join(old_folder))\n",
    "print(os.path.join(dir, folder+'_'+str(image_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f9315f",
   "metadata": {},
   "source": [
    "#### 1.3 Function for upsampling images of 256-256 or 512-512 to images with size 1024-1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f61b062",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_size = image_size\n",
    "width = new_size\n",
    "height = new_size\n",
    "dim = (width, height)\n",
    "#images = glob.glob(os.path.join(new_folder, '*.jpg')) + glob.glob(os.path.join(new_folder, '*.png'))\n",
    "\n",
    "def resize_upsampling(old_folder, new_folder):\n",
    "    for image in os.listdir(old_folder):\n",
    "        img = cv2.imread(os.path.join(old_folder, image))\n",
    "        # INTER_CUBIC or INTER_LANCZOS4\n",
    "        img_resized = cv2.resize(img, dim, interpolation = cv2.INTER_CUBIC)\n",
    "        print('Shape: '+str(img.shape)+' is now resized to: '+str(img_resized.shape))\n",
    "        cv2.imwrite(os.path.join(new_folder , image),img_resized)\n",
    "        \n",
    "def resize_downsampling(old_folder, new_folder):\n",
    "    for image in os.listdir(old_folder):\n",
    "        img = cv2.imread(os.path.join(old_folder, image))\n",
    "        img_resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "        print('Shape: '+str(img.shape)+' is now resized to: '+str(img_resized.shape))\n",
    "        cv2.imwrite(os.path.join(new_folder , image),img_resized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1419ef7",
   "metadata": {},
   "source": [
    "#### 1.4 Run the aforementoined function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2034aa99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (256, 256, 3) is now resized to: (1024, 1024, 3)\n"
     ]
    }
   ],
   "source": [
    "resize_upsampling(old_folder, new_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3334d87e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "resize_downsampling() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-e05b3b3d368b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Folder already exists'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mresize_downsampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: resize_downsampling() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5aec9d48",
   "metadata": {},
   "source": [
    "## 2. Use the annotation Tool Labelme to create polygons in JSON format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3476f5f0",
   "metadata": {},
   "source": [
    "We than use the JSON files with polygon data to create semantic segmentation mask - no instance segmentation needed, because we do not need to differenciate between distinct features. We use the bash and python skript in this directory to do the mask translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3e1dff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'$'\t\t\t\t     fid.py\t        __pycache__\n",
      " augmentation.py\t\t     imlib\t        pylib\n",
      " data.py\t\t\t     interpolation.py   README.md\n",
      " datasets\t\t\t     labelme2coco.py    resize_images_pascalvoc\n",
      " download_dataset.sh\t\t     labelme2voc.py     test.py\n",
      " FeatureConsistencyScore_1.1.ipynb   labels.txt         tf2gan\n",
      " FeatureConsistencyScore_1.2.ipynb   LICENSE\t        tf2lib\n",
      " FeatureConsistencyScore_1.3.ipynb   mask-score.ipynb   train.py\n",
      "'FeatureConsistency Score.ipynb'     module.py\n",
      " FeatureScore\t\t\t     output\n",
      "/home/molu1019/workspace/CycleGAN-Tensorflow-2\n"
     ]
    }
   ],
   "source": [
    "!ls\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3f5cd1",
   "metadata": {},
   "source": [
    "Insert the folder path as **input_dir** where the GAN transformed images with corresponding JSON label are located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2811973a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Blattfeder/Batch1_mask\n"
     ]
    }
   ],
   "source": [
    "input_dir = '/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Blattfeder/Batch1'\n",
    "output_dir = input_dir+'_mask'\n",
    "print(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "96657eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory already exists: /mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Blattfeder/Batch1_mask\r\n"
     ]
    }
   ],
   "source": [
    "!python3 labelme2voc.py $input_dir $output_dir --labels labels.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "31772350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Blattfeder/Batch1_mask/SegmentationObjectPNG\n"
     ]
    }
   ],
   "source": [
    "seg_dir = output_dir+'/SegmentationObjectPNG'\n",
    "print(seg_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0fe3750e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rgb_274321.png', 'rgb_274414.png', 'rgb_273810.png', 'rgb_274350.png', 'rgb_274227.png', 'rgb_274288.png', 'rgb_273684.png', 'rgb_273905.png', 'rgb_273715.png', 'rgb_274513.png', 'rgb_274544.png', 'rgb_274002.png', 'rgb_273747.png', 'rgb_273971.png', 'rgb_273462.png', 'rgb_273582.png', 'rgb_273366.png', 'rgb_274064.png', 'rgb_274032.png', 'rgb_273430.png']\n"
     ]
    }
   ],
   "source": [
    "GAN_mask_images = os.listdir(seg_dir)\n",
    "print(GAN_mask_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4927a244",
   "metadata": {},
   "source": [
    "## 3. Prepare Syntetic Image Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "437c79f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_Blattfeder = [149, 255, 0]\n",
    "mask_Entluefter = []\n",
    "mask_Wandlerhalter = []\n",
    "mask_Getreibeflansch = []\n",
    "mask_Abdeckung = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9b2c99",
   "metadata": {},
   "source": [
    "#### Resize syn. Masks from 1920-1080 to 1024-1024 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ccca058c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_(image, size):\n",
    "    \"\"\"Read a ndarry of images and resizes them as a square according to the given size\n",
    "    Args: \n",
    "        image: a ndarray \n",
    "        size: required new squared format\n",
    "    \"\"\"\n",
    "    dim = (size, size)\n",
    "    img = cv2.imread(image)\n",
    "    img_resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    # tp show as array use display()\n",
    "    #display(img_resized)\n",
    "    #plt.imshow(img_resized)\n",
    "    cv2.imwrite(image, img_resized)\n",
    "    return img_resized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5811e0c",
   "metadata": {},
   "source": [
    "#### Operation for reading png segmentation masks from folder path, resize, convert to greyscale and save images in 'data' array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e9ab9722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(path, size=1024, resize=None):\n",
    "    \"\"\"Read and resize images as ndarray.\n",
    "    Args:\n",
    "        path: A string, path of images.\n",
    "        size: A tuple of 2 integers,\n",
    "            (heights, widths).\n",
    "        resize: A float or None,\n",
    "            specifying how the image value should be resized.\n",
    "            If None, no scaled.\n",
    "    \"\"\"\n",
    "    \n",
    "    if resize:\n",
    "        for file in glob.glob(os.path.join(path, '*.png')):\n",
    "            img = resize_(file, size)\n",
    "    \n",
    "    img_list = [f for f in os.listdir(path) if not f.startswith(\".\")]\n",
    "    data = np.empty((len(img_list), size, size))\n",
    "    \n",
    "    for i, _path in enumerate(img_list):\n",
    "        img = Image.open(path + os.sep + _path).convert('L')\n",
    "        img = np.array(img)\n",
    "        data[i] = img\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36106426",
   "metadata": {},
   "source": [
    "### create binary images with mask as 255 (white) and background as 0 (black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7c931e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(image, compare_flag=None):\n",
    "    #print(type(image))\n",
    "    #print(image[600,600])         # returns pixel value at 600*600\n",
    "    \n",
    "    thresh = 10\n",
    "    im_bool = image > thresh\n",
    "    #print(im_bool)                # prints for every image pixel true or false\n",
    "    #print(im_bool.shape)          # returns np array size and therefore image height and lenght\n",
    "    \n",
    "    maxval = 255\n",
    "    im_bin = (image > thresh) * maxval\n",
    "    #print(im_bin)                 # prints for each image pixel 1 or 0\n",
    "    \n",
    "    im_save_bi = Image.fromarray(np.uint8(im_bin))\n",
    "    im_save_bool = Image.fromarray((im_bool))   \n",
    "   \n",
    "    #im_syn = [file for file in os.listdir(path) if file.startswith(\"Instance\")]\n",
    "        \n",
    "    return im_save_bool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d45a5e",
   "metadata": {},
   "source": [
    "### Syntetical Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "57cb737c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Blattfeder/SegmentationMasks'\n",
    "size = 1024\n",
    "data_syn = gan_op(path, size, True)\n",
    "for i, img in enumerate(data_syn):\n",
    "    data_syn[i] = binarize(img, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d4082f",
   "metadata": {},
   "source": [
    "### GAN Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe36d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in os.listdir(seg_dir):\n",
    "        im = cv2.imread(os.path.join(bool_im, image), 0)\n",
    "        f, ax = plt.subplots(1,2)\n",
    "        im = Image.fromarray(im.astype(np.uint8))\n",
    "        bbox = im.getbbox()\n",
    "        ax[0].imshow(im)\n",
    "        ax[0].set_title(f'Bbox bi: {bbox}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b170ba78",
   "metadata": {},
   "source": [
    "### GAN versus synthetical Data compared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e56a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Blattfeder/SegmentationMasks'\n",
    "size = 1024\n",
    "\n",
    "#test read and resize for syn masks\n",
    "data_syn = gan_op(path, size, True)\n",
    "    \n",
    "#test read and resize for gan masks\n",
    "data_gan = gan_op(seg_dir, 1024, True)\n",
    "\n",
    "data = np.concatenate((data_syn, data_gan), axis=0)\n",
    "\n",
    "for i, img in enumerate(data):\n",
    "    data[i] = binarize(img)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2e6950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadpolygon():\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d0c6cb",
   "metadata": {},
   "source": [
    "Since True is regarded as 1 and False is regarded as 0, when multiplied by 255 which is the Max value of uint8, True becomes 255 (white) and False becomes 0 (black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704b5089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3522ce35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convexhull():\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d014be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculatescore(ground_truth, prediction_gan):\n",
    "    \"\"\"\n",
    "    Compute feature consitency score of two segmentation masks.\n",
    "    \n",
    "    IoU(A,B) = |A & B| / (| A U B|)\n",
    "    Dice(A,B) = 2*|A & B| / (|A| + |B|)\n",
    "\n",
    "    Args:\n",
    "        y_true: true masks, one-hot encoded.\n",
    "        y_pred: predicted masks, either softmax outputs, or one-hot encoded.\n",
    "        metric_name: metric to be computed, either 'iou' or 'dice'.\n",
    "        metric_type: one of 'standard' (default), 'soft', 'naive'.\n",
    "          In the standard version, y_pred is one-hot encoded and the mean\n",
    "          is taken only over classes that are present (in y_true or y_pred).\n",
    "          The 'soft' version of the metrics are computed without one-hot\n",
    "          encoding y_pred.\n",
    "          The 'naive' version return mean metrics where absent classes contribute\n",
    "          to the class mean as 1.0 (instead of being dropped from the mean).\n",
    "        drop_last = True: boolean flag to drop last class (usually reserved\n",
    "          for background class in semantic segmentation)\n",
    "        mean_per_class = False: return mean along batch axis for each class.\n",
    "        verbose = False: print intermediate results such as intersection, union\n",
    "          (as number of pixels).\n",
    "    Returns:\n",
    "        IoU of ground truth and GAN transformed syntetic Image, as a float.\n",
    "\n",
    "    Inputs are B*W*H*N tensors, with\n",
    "        B = batch size,\n",
    "        W = width,\n",
    "        H = height,\n",
    "        N = number of classes\n",
    "    \"\"\"\n",
    "    \n",
    "    # check image shape to be the same\n",
    "    assert ground_truth.shape == prediction_gan.shape, 'Input masks should be same shape, instead are {}, {}'.format(ground_truth.shape, prediction_gan.shape)\n",
    "    print('Ground truth shape: '+str(ground_truth.shape))\n",
    "    print('Predicted GAN image shape: '+str(prediction_gan.shape))\n",
    "    \n",
    "    intersection = np.logical_and(ground_truth, prediction_gan)\n",
    "    union = np.logical_or(ground_truth, prediction_gan)\n",
    "    mask_sum = np.sum(np.abs(union)) + np.sum(np.abs(intersection))\n",
    "    iou_score = np.sum(intersection) / np.sum(union)\n",
    "    dice_score = 2*np.sum(intersection) / np.sum(mask_sum) \n",
    "    print('IoU is: '+str(iou_score))\n",
    "    print('Dice/F1 Score is: '+str(dice_score))\n",
    "    return iou_score, dice_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca46ef52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test calculation \n",
    "calculatescore(data_syn, data_gan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7713902d",
   "metadata": {},
   "source": [
    "### Image mask transformation \n",
    "Translate image mask to white RGB(255,255,255), fill convex hull, and compare masks to calculate 'Feature Consistency Score' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced4a014",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in glob.glob(\"*.png\"):\n",
    "    calculatescore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25fc466",
   "metadata": {},
   "source": [
    "## Print Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4659997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9187dd07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('cygan': virtualenv)",
   "language": "python",
   "name": "python369jvsc74a57bd0987972a5af0063b4ad0c1bc948181328354b4e09dc76cc55a6609915adabc773"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
