{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a06cd1d4",
   "metadata": {},
   "source": [
    "## Notebook for calculating Mask Consistency Score for GAN-transformed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "900e2b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import glob, os\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.image as mpimg\n",
    "#from keras.preprocessing.image import img_to_array, array_to_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8306f81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_GAN = '/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Wandlerhalter/Batch4_joint_WH'\n",
    "path_Masks_1024 = '/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Wandlerhalter/SegmentationMasks_1024'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd58ed4",
   "metadata": {},
   "source": [
    "## 1. Resize GAN-transformed Dataset to 1024*1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00c6def",
   "metadata": {},
   "source": [
    "#### 1.1 Specify Args: Directory, folder name and the new image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bab0c67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = '/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Powertrain18_all/Results/Batch1_Size512/samples_testing_Entluefter'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b400c36",
   "metadata": {},
   "source": [
    "#### 1.2 Create new Folder \"/A2B_FID_1024\" in Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "520e04ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists\n"
     ]
    }
   ],
   "source": [
    "folder = 'A2B_FID'\n",
    "image_size = 1024\n",
    "old_folder = (os.path.join(dir, folder))\n",
    "new_folder = (os.path.join(dir, folder+'_'+str(image_size)))\n",
    "\n",
    "if os.path.exists(new_folder):\n",
    "    try:\n",
    "        os.mkdir(new_folder)\n",
    "    except FileExistsError:\n",
    "        print('Folder already exists')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "76b37952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Powertrain18_all/Results/Batch1_Size512/samples_testing_Entluefter/A2B_FID\n",
      "/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Powertrain18_all/Results/Batch1_Size512/samples_testing_Entluefter/A2B_FID_1024\n"
     ]
    }
   ],
   "source": [
    "print(os.path.join(old_folder))\n",
    "print(os.path.join(dir, folder+'_'+str(image_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f9315f",
   "metadata": {},
   "source": [
    "#### 1.3 Function for upsampling images of 256-256 or 512-512 to images with size 1024-1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f61b062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_upsampling(old_folder, new_folder, size):\n",
    "    dim = (size, size)\n",
    "    for image in os.listdir(old_folder):\n",
    "        img = cv2.imread(os.path.join(old_folder, image))\n",
    "        # INTER_CUBIC or INTER_LANCZOS4\n",
    "        img_resized = cv2.resize(img, dim, interpolation = cv2.INTER_LANCZOS4)\n",
    "        print('Shape: '+str(img.shape)+' is now resized to: '+str(img_resized.shape))\n",
    "        cv2.imwrite(os.path.join(new_folder , image),img_resized)\n",
    "        \n",
    "def resize_downsampling(old_folder, new_folder, size):\n",
    "    dim = (size, size)\n",
    "    for image in os.listdir(old_folder):\n",
    "        img = cv2.imread(os.path.join(old_folder, image))\n",
    "        img_resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "        print('Shape: '+str(img.shape)+' is now resized to: '+str(img_resized.shape))\n",
    "        cv2.imwrite(os.path.join(new_folder , image),img_resized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1419ef7",
   "metadata": {},
   "source": [
    "#### 1.4 Run the aforementoined function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2034aa99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1080, 1920, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (1080, 1920, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (1080, 1920, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (1080, 1920, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (1080, 1920, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (1080, 1920, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (1080, 1920, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (1080, 1920, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (1080, 1920, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (1080, 1920, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (1080, 1920, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (1080, 1920, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (1080, 1920, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (1080, 1920, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (1080, 1920, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (1080, 1920, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (1080, 1920, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (1080, 1920, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (1080, 1920, 3) is now resized to: (1024, 1024, 3)\n",
      "Shape: (1080, 1920, 3) is now resized to: (1024, 1024, 3)\n"
     ]
    }
   ],
   "source": [
    "resize_upsampling(old_folder, new_folder, 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa3d6de",
   "metadata": {},
   "source": [
    "#### Resize the syntetic image masks to 1024-1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "02e5aa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir2 = '/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Wandlerhalter'\n",
    "folder = 'SegmentationMasks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a4c07467",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "size = 1024\n",
    "old_folder = (os.path.join(dir2, folder))\n",
    "masks_syn_1024 = (os.path.join(dir2, folder+'_'+str(size)))\n",
    "\n",
    "if os.path.exists(masks_syn_1024):\n",
    "    try:\n",
    "        os.mkdir(masks_syn_1024)\n",
    "    except FileExistsError:\n",
    "        print('Folder already exists')\n",
    "resize_downsampling(old_folder, masks_syn_1024, size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aec9d48",
   "metadata": {},
   "source": [
    "## 2. Use the annotation Tool Labelme to create polygons for GAN Images in JSON format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3476f5f0",
   "metadata": {},
   "source": [
    "We than use the JSON files with polygon data to create semantic segmentation mask - no instance segmentation needed, because we do not need to differenciate between distinct features. We use the bash and python skript in this directory to do the mask translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e3e1dff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmentation.py\n",
      "data.py\n",
      "datasets\n",
      "download_dataset.sh\n",
      "FeatureConsistencyScore_2.0-BlattfederBatch1.ipynb\n",
      "FeatureConsistencyScore_2.0-BlattfederBatch2.ipynb\n",
      "FeatureConsistencyScore_2.0-BlattfederBatch4.ipynb\n",
      "FeatureConsistencyScore_2.0-EntluefterBatch1.ipynb\n",
      "FeatureConsistencyScore_2.0-EntluefterBatch2.ipynb\n",
      "FeatureConsistencyScore_2.0.ipynb\n",
      "FeatureConsistencyScore_2.1-EntluefterBatch4.ipynb\n",
      "FeatureConsistencyScore_2.1-GetriebeflanschBatch1.ipynb\n",
      "FeatureConsistencyScore_2.2-GetriebeflanschBatch1.ipynb\n",
      "FeatureConsistencyScore_2.2-GetriebeflanschBatch2.ipynb\n",
      "FeatureConsistencyScore_2.2-GetriebeflanschBatch4.ipynb\n",
      "FeatureConsistencyScore_2.2-PT18-BlattfederBatch1-2-4.ipynb\n",
      "FeatureConsistencyScore_2.2-PT18-EntluefterBatch1-2-4.ipynb\n",
      "FeatureConsistencyScore_2.2-PT18-GetriebeflanschBatch1-2-4.ipynb\n",
      "FeatureConsistencyScore_2.2-PT18-WandlerhalterBatch1-2-4.ipynb\n",
      "FeatureConsistencyScore_2.2-WandlerhalterBatch1.ipynb\n",
      "FeatureConsistencyScore_2.2-WandlerhalterBatch2.ipynb\n",
      "FeatureConsistencyScore_2.2-WandlerhalterBatch4.ipynb\n",
      "fid.py\n",
      "filename.txt\n",
      "imlib\n",
      "interpolation.py\n",
      "labelme2coco.py\n",
      "labelme2voc.py\n",
      "labels.txt\n",
      "LICENSE\n",
      "mask-score.ipynb\n",
      "module.py\n",
      "Notebook_Archive\n",
      "output\n",
      "path\n",
      "__pycache__\n",
      "pylib\n",
      "README.md\n",
      "resize_images_pascalvoc\n",
      "test.py\n",
      "tf2gan\n",
      "tf2lib\n",
      "train.py\n",
      "/home/molu1019/workspace/CycleGAN-Tensorflow-2\n"
     ]
    }
   ],
   "source": [
    "!ls\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3f5cd1",
   "metadata": {},
   "source": [
    "Insert the folder path as **input_dir** where the GAN transformed images with corresponding JSON label are located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2811973a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Wandlerhalter/Batch4_joint_WH_mask\n"
     ]
    }
   ],
   "source": [
    "input_dir = path_GAN\n",
    "output_dir = input_dir+'_mask'\n",
    "print(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96657eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory already exists: /mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Wandlerhalter/Batch4_joint_WH_mask\r\n"
     ]
    }
   ],
   "source": [
    "!python3 labelme2voc.py $input_dir $output_dir --labels labels.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31772350",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_gan = output_dir+'/SegmentationObjectPNG'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c93cbb",
   "metadata": {},
   "source": [
    "## 3. GAN Image Data\n",
    "### 3.1 Prepare Data: Create Folder with binary images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "8427b343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(im_path, threshold=10):\n",
    "    \"\"\"Read, binarize and save images as png.\n",
    "    Args:\n",
    "        path: Path for folder of png images.\n",
    "    \"\"\"\n",
    "    masks_binarized = im_path+'_binarized'\n",
    "    os.mkdir(masks_binarized)\n",
    "    \n",
    "    print(im_path)\n",
    "    print(masks_binarized)\n",
    "    \n",
    "    path = os.path.join(im_path, '*.png')\n",
    "    files = list(glob.glob(path))\n",
    "    files.sort(reverse=True)\n",
    "    print(files)\n",
    "    \n",
    "    for file in files:\n",
    "        size=1024\n",
    "        img = Image.open(file).convert('L')\n",
    "        img = np.array(img)\n",
    "        #print(img[210,:-50])\n",
    "\n",
    "        # störungen im Bild:\n",
    "        #16 128 148  35 31 143 153 16 128 153 153 153 153 127  15   0  10 116  35\n",
    "        thresh = threshold\n",
    "        Flansch = 89\n",
    "        Abdeckung = 76\n",
    "        Mutter =174\n",
    "        Wandler_stoerung= 153\n",
    "        Wandler = 157\n",
    "\n",
    "        im_bool = img > thresh\n",
    "        #im_bool = np.logical_or(img == Wandler, img ==4)    \n",
    "        #im_bool = img == Wandler\n",
    "\n",
    "        maxval = 255\n",
    "        im_bin = (img > thresh) * maxval\n",
    "\n",
    "        #save array to images\n",
    "        im_save_bi = Image.fromarray(np.uint8(im_bin))\n",
    "        im_save_bool = Image.fromarray((im_bool))\n",
    "        \n",
    "        image = im_save_bool\n",
    "        plt.imshow(image)\n",
    "        bbox = image.getbbox()\n",
    "        plt.title(f'Bbox: {bbox} Name: {file[-10:]}')\n",
    "        image.save(os.path.join(masks_binarized,file[-10:]))\n",
    "\n",
    "    #return im_save_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "f48a8d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Wandlerhalter/Batch4_joint_WH_mask/SegmentationObjectPNG\n",
      "/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Wandlerhalter/Batch4_joint_WH_mask/SegmentationObjectPNG_binarized\n"
     ]
    }
   ],
   "source": [
    "#test GAN Data\n",
    "masks_gan = path_GAN+'_mask'+'/SegmentationObjectPNG'\n",
    "masks_gan_binarized = masks_gan+'_binarized'\n",
    "print(masks_gan)\n",
    "print(masks_gan_binarized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "95c02e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Wandlerhalter/Batch4_joint_WH_mask/SegmentationObjectPNG\n",
      "/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Wandlerhalter/Batch4_joint_WH_mask/SegmentationObjectPNG_binarized\n",
      "['/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Wandlerhalter/Batch4_joint_WH_mask/SegmentationObjectPNG/rgb_19897.png', '/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Wandlerhalter/Batch4_joint_WH_mask/SegmentationObjectPNG/rgb_19863.png', '/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Wandlerhalter/Batch4_joint_WH_mask/SegmentationObjectPNG/rgb_19796.png', '/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Wandlerhalter/Batch4_joint_WH_mask/SegmentationObjectPNG/rgb_19764.png', '/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Wandlerhalter/Batch4_joint_WH_mask/SegmentationObjectPNG/rgb_19634.png', '/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Wandlerhalter/Batch4_joint_WH_mask/SegmentationObjectPNG/rgb_19601.png', '/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Wandlerhalter/Batch4_joint_WH_mask/SegmentationObjectPNG/rgb_19537.png', '/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Wandlerhalter/Batch4_joint_WH_mask/SegmentationObjectPNG/rgb_19470.png', '/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Wandlerhalter/Batch4_joint_WH_mask/SegmentationObjectPNG/rgb_19402.png', '/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Wandlerhalter/Batch4_joint_WH_mask/SegmentationObjectPNG/rgb_19369.png', '/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Wandlerhalter/Batch4_joint_WH_mask/SegmentationObjectPNG/rgb_19335.png', '/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Wandlerhalter/Batch4_joint_WH_mask/SegmentationObjectPNG/rgb_19266.png', '/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Wandlerhalter/Batch4_joint_WH_mask/SegmentationObjectPNG/rgb_19134.png', '/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Wandlerhalter/Batch4_joint_WH_mask/SegmentationObjectPNG/rgb_19103.png', '/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Wandlerhalter/Batch4_joint_WH_mask/SegmentationObjectPNG/rgb_19069.png', '/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Wandlerhalter/Batch4_joint_WH_mask/SegmentationObjectPNG/rgb_19001.png', '/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Wandlerhalter/Batch4_joint_WH_mask/SegmentationObjectPNG/rgb_18967.png', '/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Wandlerhalter/Batch4_joint_WH_mask/SegmentationObjectPNG/rgb_18932.png', '/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Wandlerhalter/Batch4_joint_WH_mask/SegmentationObjectPNG/rgb_18829.png', '/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Wandlerhalter/Batch4_joint_WH_mask/SegmentationObjectPNG/rgb_18794.png']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not os.path.exists(masks_gan_binarized):\n",
    "    binarize(masks_gan)\n",
    "else: \n",
    "    print(f'Path: {masks_gan_binarized} binarized syntetic polygon masks already exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4927a244",
   "metadata": {},
   "source": [
    "## 4. Syntetic Image Masks\n",
    "### 4.1 Prepare Data: Create Folder with binary images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5811e0c",
   "metadata": {},
   "source": [
    "#### Operation for reading png segmentation masks from folder path, resize, convert to greyscale and save imagesin new folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2ed2eddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Wandlerhalter/SegmentationMasks_1024\n",
      "/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Wandlerhalter/SegmentationMasks_1024_binarized\n"
     ]
    }
   ],
   "source": [
    "masks_syn = path_Masks_1024\n",
    "masks_syn_binarized = masks_syn+'_binarized'\n",
    "print(masks_syn)\n",
    "print(masks_syn_binarized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e9ab9722",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists\n"
     ]
    }
   ],
   "source": [
    "#test Syn Data\n",
    "if not os.path.exists(masks_syn_binarized):\n",
    "    os.mkdir(masks_syn_binarized)\n",
    "    \n",
    "    path = os.path.join(masks_syn, '*.png')\n",
    "    files = list(glob.glob(path))\n",
    "    files.sort(reverse=True)\n",
    "\n",
    "    for file in files:\n",
    "        image = binarize(file, threshold=50)\n",
    "        plt.imshow(image)\n",
    "        bbox = image.getbbox()\n",
    "        plt.title(f'Bbox: {bbox} Name: {file[-18:]}')\n",
    "        image.save(os.path.join(masks_syn_binarized,file[-18:]))\n",
    "else:\n",
    "    print('Folder already exists')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "1d6117f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binarized syntetic polygon masks already exists:\n",
      "/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Wandlerhalter/SegmentationMasks_1024_binarized\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(masks_syn_binarized):\n",
    "    binarize(masks_syn)\n",
    "else:\n",
    "    print(f'Binarized syntetic polygon masks already exists:\\n{masks_syn_binarized}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4d2e6950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadpolygon():\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d0c6cb",
   "metadata": {},
   "source": [
    "Since True is regarded as 1 and False is regarded as 0, when multiplied by 255 which is the Max value of uint8, True becomes 255 (white) and False becomes 0 (black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "9b8f89f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Wandlerhalter/SegmentationMasks_1024_binarized_convex\n"
     ]
    }
   ],
   "source": [
    "masks_syn_binarized = path_Masks_1024+'_binarized'\n",
    "masks_syn_binarized_filled = masks_syn_binarized+'_convex'\n",
    "print(masks_syn_binarized_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "3522ce35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled binarized syntetic polygon masks already exists:\n",
      "/mnt/robolab/data/Bilddaten/GAN_train_data_sydavis-ai/Evaluation/BatchSize/Wandlerhalter/SegmentationMasks_1024_binarized_convex\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(masks_syn_binarized_filled):\n",
    "    fill_polygon(masks_syn_binarized)\n",
    "else: \n",
    "    print(f'Filled binarized syntetic polygon masks already exists:\\n{masks_syn_binarized_filled}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "2f05058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_polygon(path):\n",
    "    masks_binarized = path\n",
    "    masks_binarized_filled = masks_binarized+'_convex'\n",
    "    os.mkdir(masks_binarized_filled)\n",
    "    path_bin = os.path.join(masks_binarized, '*.png')\n",
    "    files = list(glob.glob(path_bin))\n",
    "    files.sort(reverse=True)\n",
    "    \n",
    "    for file in files:\n",
    "        image = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        #print(image.shape, image.dtype)\n",
    "        contour,hierarchy = cv2.findContours(image,cv2.RETR_CCOMP,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        for cnt in contour:\n",
    "            cv2.drawContours(image,[cnt],0,255,-1)\n",
    "\n",
    "            #image = cv2.bitwise_not(image)\n",
    "            image.dtype\n",
    "            plt.imshow(image)\n",
    "            #bbox = image.getbbox()\n",
    "            plt.title(f'Bbox: {bbox} Name: {file[-18:]}')\n",
    "            cv2.imwrite(os.path.join(masks_binarized_filled,file[-18:]),image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "09d014be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculatescore(ground_truth, prediction_gan):\n",
    "    \"\"\"\n",
    "    Compute feature consitency score of two segmentation masks.\n",
    "    \n",
    "    IoU(A,B) = |A & B| / (| A U B|)\n",
    "    Dice(A,B) = 2*|A & B| / (|A| + |B|)\n",
    "\n",
    "    Args:\n",
    "        y_true: true masks, one-hot encoded.\n",
    "        y_pred: predicted masks, either softmax outputs, or one-hot encoded.\n",
    "        metric_name: metric to be computed, either 'iou' or 'dice'.\n",
    "        metric_type: one of 'standard' (default), 'soft', 'naive'.\n",
    "          In the standard version, y_pred is one-hot encoded and the mean\n",
    "          is taken only over classes that are present (in y_true or y_pred).\n",
    "          The 'soft' version of the metrics are computed without one-hot\n",
    "          encoding y_pred.\n",
    "          \n",
    "    Returns:\n",
    "        IoU of ground truth and GAN transformed syntetic Image, as a float.\n",
    "\n",
    "    Inputs are B*W*H*N tensors, with\n",
    "        B = batch size,\n",
    "        W = width,\n",
    "        H = height,\n",
    "        N = number of classes\n",
    "    \"\"\"\n",
    "    \n",
    "    # check image shape to be the same\n",
    "    assert ground_truth.shape == prediction_gan.shape, 'Input masks should be same shape, instead are {}, {}'.format(ground_truth.shape, prediction_gan.shape)\n",
    "    #print('Ground truth shape: '+str(ground_truth.shape))\n",
    "    #print('Predicted GAN image shape: '+str(prediction_gan.shape))\n",
    "    \n",
    "    intersection = np.logical_and(ground_truth, prediction_gan)\n",
    "    union = np.logical_or(ground_truth, prediction_gan)\n",
    "    mask_sum = np.sum(np.abs(union)) + np.sum(np.abs(intersection))\n",
    "    iou_score = np.sum(intersection) / np.sum(union)\n",
    "    dice_score = 2*np.sum(intersection) / np.sum(mask_sum) \n",
    "    print('IoU is: '+str(iou_score))\n",
    "    print('Dice/F1 Score is: '+str(dice_score))\n",
    "    return iou_score, dice_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7713902d",
   "metadata": {},
   "source": [
    "## 6. Calculate mean IoU\n",
    "Translate image mask to white RGB(255,255,255), fill convex hull, and compare masks to calculate 'Feature Consistency Score' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "ced4a014",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_syn = masks_syn_binarized_filled\n",
    "path_gan = masks_gan_binarized\n",
    "path_syn = os.path.join(path_syn, '*.png')\n",
    "path_gan = os.path.join(path_gan, '*.png')\n",
    "files_syn = list(glob.glob(path_syn))\n",
    "files_gan = list(glob.glob(path_gan))\n",
    "files_syn.sort(reverse=True)\n",
    "files_gan.sort(reverse=True)\n",
    "\n",
    "combined_list = zip(files_syn, files_gan)\n",
    "z = list(combined_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "6806b2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image name: 19897.png\n",
      "IoU is: 0.9736005222629869\n",
      "Dice/F1 Score is: 0.9866236974305506\n",
      "\n",
      "\n",
      "Image name: 19863.png\n",
      "IoU is: 0.968849250313908\n",
      "Dice/F1 Score is: 0.9841781946072685\n",
      "\n",
      "\n",
      "Image name: 19796.png\n",
      "IoU is: 0.9740033226413618\n",
      "Dice/F1 Score is: 0.986830479432095\n",
      "\n",
      "\n",
      "Image name: 19764.png\n",
      "IoU is: 0.9619138120880281\n",
      "Dice/F1 Score is: 0.9805872267796324\n",
      "\n",
      "\n",
      "Image name: 19634.png\n",
      "IoU is: 0.9653466179712876\n",
      "Dice/F1 Score is: 0.9823678013273389\n",
      "\n",
      "\n",
      "Image name: 19601.png\n",
      "IoU is: 0.969461436532283\n",
      "Dice/F1 Score is: 0.9844939520514361\n",
      "\n",
      "\n",
      "Image name: 19537.png\n",
      "IoU is: 0.960609243697479\n",
      "Dice/F1 Score is: 0.979908920439325\n",
      "\n",
      "\n",
      "Image name: 19470.png\n",
      "IoU is: 0.9587670595627193\n",
      "Dice/F1 Score is: 0.978949543675456\n",
      "\n",
      "\n",
      "Image name: 19402.png\n",
      "IoU is: 0.9595617602872742\n",
      "Dice/F1 Score is: 0.979363630923887\n",
      "\n",
      "\n",
      "Image name: 19369.png\n",
      "IoU is: 0.9701530255616135\n",
      "Dice/F1 Score is: 0.9848504283417892\n",
      "\n",
      "\n",
      "Image name: 19335.png\n",
      "IoU is: 0.9727713865110954\n",
      "Dice/F1 Score is: 0.9861977856759879\n",
      "\n",
      "\n",
      "Image name: 19266.png\n",
      "IoU is: 0.967900641025641\n",
      "Dice/F1 Score is: 0.9836885265926693\n",
      "\n",
      "\n",
      "Image name: 19134.png\n",
      "IoU is: 0.969251646926453\n",
      "Dice/F1 Score is: 0.9843857674962273\n",
      "\n",
      "\n",
      "Image name: 19103.png\n",
      "IoU is: 0.9669104752127978\n",
      "Dice/F1 Score is: 0.9831769034716121\n",
      "\n",
      "\n",
      "Image name: 19069.png\n",
      "IoU is: 0.9735385187379819\n",
      "Dice/F1 Score is: 0.9865918597429052\n",
      "\n",
      "\n",
      "Image name: 19001.png\n",
      "IoU is: 0.9703575398774592\n",
      "Dice/F1 Score is: 0.9849557963351239\n",
      "\n",
      "\n",
      "Image name: 18967.png\n",
      "IoU is: 0.9653416654654604\n",
      "Dice/F1 Score is: 0.9823652369745434\n",
      "\n",
      "\n",
      "Image name: 18932.png\n",
      "IoU is: 0.9761731743975591\n",
      "Dice/F1 Score is: 0.9879429465437893\n",
      "\n",
      "\n",
      "Image name: 18829.png\n",
      "IoU is: 0.9740369763873894\n",
      "Dice/F1 Score is: 0.9868477521327262\n",
      "\n",
      "\n",
      "Image name: 18794.png\n",
      "IoU is: 0.9708953675620672\n",
      "Dice/F1 Score is: 0.9852327866222882\n",
      "\n",
      "\n",
      "Mean IoU is: 0.9684721721511422\n",
      "[0.9736005222629869, 0.968849250313908, 0.9740033226413618, 0.9619138120880281, 0.9653466179712876, 0.969461436532283, 0.960609243697479, 0.9587670595627193, 0.9595617602872742, 0.9701530255616135, 0.9727713865110954, 0.967900641025641, 0.969251646926453, 0.9669104752127978, 0.9735385187379819, 0.9703575398774592, 0.9653416654654604, 0.9761731743975591, 0.9740369763873894, 0.9708953675620672]\n",
      "\n",
      "Mean Dice score is: 0.9839769618298325\n",
      "[0.9866236974305506, 0.9841781946072685, 0.986830479432095, 0.9805872267796324, 0.9823678013273389, 0.9844939520514361, 0.979908920439325, 0.978949543675456, 0.979363630923887, 0.9848504283417892, 0.9861977856759879, 0.9836885265926693, 0.9843857674962273, 0.9831769034716121, 0.9865918597429052, 0.9849557963351239, 0.9823652369745434, 0.9879429465437893, 0.9868477521327262, 0.9852327866222882]\n"
     ]
    }
   ],
   "source": [
    "iou_list = []\n",
    "dice_list = []\n",
    "for syn, gan in zip(files_syn, files_gan):\n",
    "    img_syn = np.array(Image.open(syn))\n",
    "    img_gan = np.array(Image.open(gan))\n",
    "    print(f'Image name: {syn[-9:]}')\n",
    "    iou, dice = calculatescore(img_syn, img_gan)\n",
    "    print('\\n')\n",
    "    iou_list.append(iou)\n",
    "    dice_list.append(dice)\n",
    "    \n",
    "mean_iou = np.mean(iou_list)\n",
    "mean_dice = np.mean(dice_list)\n",
    "print(f'Mean IoU is: {mean_iou}')\n",
    "print(f'{iou_list}\\n')\n",
    "print(f'Mean Dice score is: {mean_dice}')\n",
    "print(dice_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "6de20a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "base_dir = input_dir\n",
    "prefix = 'batch4'\n",
    "score_name = prefix+'_score.txt'\n",
    "path = os.path.join(base_dir,score_name)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    try:\n",
    "        os.mknod(path)\n",
    "    except FileExistsError:\n",
    "        print('Folder already exists')\n",
    "        pass \n",
    "\n",
    "original_stdout = sys.stdout             # Save a reference to the original standard output\n",
    "\n",
    "with open(path, 'w') as f:\n",
    "    sys.stdout = f                       # Change the standard output to the file we created.\n",
    "    iou_list = []\n",
    "    dice_list = []\n",
    "    print(f'Consistency Metrics for {prefix}:\\n')\n",
    "    for syn, gan in zip(files_syn, files_gan):\n",
    "        img_syn = np.array(Image.open(syn))\n",
    "        img_gan = np.array(Image.open(gan))\n",
    "        print(f'Image name: {syn[-9:]}')\n",
    "        iou, dice = calculatescore(img_syn, img_gan)\n",
    "        print('\\n')\n",
    "        iou_list.append(iou)\n",
    "        dice_list.append(dice)\n",
    "\n",
    "    mean_iou = np.mean(iou_list)\n",
    "    mean_dice = np.mean(dice_list)\n",
    "    print(f'Mean IoU is: {mean_iou}')\n",
    "    print(f'{iou_list}\\n')\n",
    "    print(f'Mean Dice score is: {mean_dice}')\n",
    "    print(dice_list)\n",
    "    sys.stdout = original_stdout         # Reset the standard output to its original value\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb912309",
   "metadata": {},
   "outputs": [],
   "source": [
    "#overlapping of 2 masks\n",
    "#Image.blend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('cygan': virtualenv)",
   "language": "python",
   "name": "python369jvsc74a57bd0987972a5af0063b4ad0c1bc948181328354b4e09dc76cc55a6609915adabc773"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
